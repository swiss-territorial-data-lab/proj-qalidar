{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "import laspy\n",
    "import time\n",
    "import pathlib\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refer to the criticity tree made on lucid chart for the definition of the criticity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../out_dataframe/voxelised_comparison'\n",
    "file_name = '2546500_1212000_150-150.csv'\n",
    "\n",
    "save_folder_path = '../out_dataframe/criticity_changes_df'\n",
    "\n",
    "# Create the path for the folder to store the .csv file in case it doesn't yet exist\n",
    "pathlib.Path(save_folder_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_name, voxel_dimension = file_name.replace('.csv','').rsplit('_', maxsplit=1) \n",
    "vox_width_str, vox_height_str = voxel_dimension.split('-')\n",
    "\n",
    "vox_width = float(vox_width_str)/100    # Must convert the voxel height/width from centimeters to meters\n",
    "vox_height = float(vox_height_str)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters definition:\n",
    "#TODO: Important parameters, must be tuned!\n",
    "# Decision C (Voxels with cosine similarity above this threshold are consider non problematic)\n",
    "cos_threshold = 0.8\n",
    "# Decision D\n",
    "second_cos_threshold=0.8\n",
    "# Decision E\n",
    "third_cosine_threshold = 0.8\n",
    "# Decision F (If the normalised number of unclassified points in a voxel of the new generation is lower than this threshold, voxel is considered non problematic)\n",
    "threshold_class_1_presence = 1\n",
    "# Decisions H and I (Defines the radius of resarch for similar neighbours)\n",
    "# If using vox_height: up to 6 neighbours\n",
    "# -- ----- 2**(1/2)*vox_height: up to 18 neighbours\n",
    "# -- ----- 3**(1/2)*vox_height: up to 26 neighbours\n",
    "kd_tree_query_radius = 2**(1/2)*vox_height "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(folder_path,file_name))\n",
    "\n",
    "df['change_criticity'] = 'TBD' # Set all change criticities to TBD = To be determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision A: Is there only one class in both generation, and is it the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_to_evaluate = df[df['change_criticity']=='TBD']\n",
    "voxels_to_evaluate_prev = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_prev')].values.astype(bool)\n",
    "voxels_to_evaluate_new = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_new')].values.astype(bool)\n",
    "\n",
    "mask = (voxels_to_evaluate_prev.sum(axis=1)==1) & (voxels_to_evaluate_new.sum(axis=1)==1) & (np.all(voxels_to_evaluate_prev==voxels_to_evaluate_new, axis=1))\n",
    "\n",
    "# Set criticity to 'non_prob_1' for rows for which the mask is True\n",
    "df.loc[voxels_to_evaluate.index, 'change_criticity'] = np.where(mask==True, 'non_prob-1','TBD') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['change_criticity']=='non_prob-1'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision B: 'Is there noise in the new voxel?'\n",
    "#### Originaly was : Is the new class anything else but noise? but changed to this for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['7_new']>0,'change_criticity'] = 'problematic-13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['change_criticity']=='problematic-13'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision C: Does the number of class and distribution stay the same? \n",
    "**Currently using cosine similarity to evaluate this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cosine_similarity'] = np.where(df['change_criticity']=='TBD', 0, 1.0) # Set cosine similarity to 1 for all already determined voxels\n",
    "\n",
    "voxels_to_evaluate =  df[df['change_criticity']=='TBD']\n",
    "\n",
    "# Compute cosine similarity\n",
    "voxels_to_evaluate_prev = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_prev')].values\n",
    "voxels_to_evaluate_new = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_new')].values\n",
    "dot_product = np.sum(voxels_to_evaluate_prev * voxels_to_evaluate_new, axis=1)\n",
    "product_of_norm = np.linalg.norm(voxels_to_evaluate_prev, axis=1)*np.linalg.norm(voxels_to_evaluate_new, axis=1)\n",
    "\n",
    "# For cases where one vector is completely empty, avoid division by zero and replace by -1\n",
    "cosine_similarity = np.divide(dot_product, product_of_norm, out = np.full_like(dot_product, -1), where = product_of_norm!=0)\n",
    "df.loc[df['change_criticity']=='TBD', 'cosine_similarity'] = cosine_similarity\n",
    "\n",
    "# Mask where True if the boolean presence of the classes are exactly the same in both generation\n",
    "same_class_present = np.all(df.iloc[:, df.columns.str.endswith('_prev')].values.astype(bool) == df.iloc[:, df.columns.str.endswith('_new')].values.astype(bool), axis=1)\n",
    "\n",
    "df.loc[(df['cosine_similarity']>cos_threshold) & (df['change_criticity']=='TBD') & (same_class_present), 'change_criticity'] = 'non_prob-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['change_criticity']=='non_prob-2'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision D: Do the previous classes keep the same distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the cosine similarity only between classes which are present in the previous generation \n",
    "Note: if only one class is present in the previous generation, the cosine similarity is either 1 or -1 (unvalid division) which doesn't provide much info, possibly compare euclidean distance between the normalised density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_to_evaluate = df[df['change_criticity']=='TBD']\n",
    "\n",
    "df['second_cosine_similarity'] = np.nan\n",
    "\n",
    "voxels_to_evaluate_prev = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_prev')].values\n",
    "voxels_to_evaluate_new = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_new')].values\n",
    "dot_product = np.sum(voxels_to_evaluate_prev * voxels_to_evaluate_new, axis=1)\n",
    "# For new vector, only take values for which class is present in the previous vector\n",
    "product_of_norm = np.linalg.norm(voxels_to_evaluate_prev, axis=1)*np.linalg.norm(voxels_to_evaluate_prev.astype(bool) * voxels_to_evaluate_new, axis=1) \n",
    "\n",
    "# For cases where one vector is completely empty, avoid division by zero and replace by -1\n",
    "cosine_similarity = np.divide(dot_product, product_of_norm, out = np.full_like(dot_product, -1), where = product_of_norm!=0)\n",
    "\n",
    "df.loc[voxels_to_evaluate.index, 'second_cosine_similarity'] = cosine_similarity\n",
    "\n",
    "# Added condition of 'df.cosine_similarity!=-1' as this represent cases of complete disparition in the voxel which we want to keep for decision G\n",
    "df.loc[(df.second_cosine_similarity<second_cos_threshold) & (df.cosine_similarity!=-1), 'change_criticity']='problematic-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['change_criticity']=='problematic-12'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision E: is the change due to class 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compare whether the voxels are similar if we don't consider the unclassified points. If they stay the same, \n",
    "# it means the difference comes from unclassified point.  \n",
    "voxels_to_evaluate = df[df['change_criticity']=='TBD'].drop(columns=['1_prev','1_new'])\n",
    "\n",
    "# For the specific cases of apparition or disparition only due to class 1, find rows which are empty for prev. and new gen. when not\n",
    "# considering the class 1\n",
    "mask_disparition_apparition = (voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.contains('_prev|_new')].values).sum(axis=1)==0\n",
    "df.loc[voxels_to_evaluate[mask_disparition_apparition].index, 'change_criticity'] = 'class_1_specific'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='class_1_specific'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels_to_evaluate = df[df['change_criticity']=='TBD'].drop(columns=['1_prev','1_new'])\n",
    "voxels_to_evaluate_prev = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_prev')].values\n",
    "voxels_to_evaluate_new = voxels_to_evaluate.iloc[:, voxels_to_evaluate.columns.str.endswith('_new')].values\n",
    "dot_product = np.sum(voxels_to_evaluate_prev * voxels_to_evaluate_new, axis=1)\n",
    "\n",
    "product_of_norm = np.linalg.norm(voxels_to_evaluate_prev, axis=1)*np.linalg.norm(voxels_to_evaluate_new, axis=1) \n",
    "\n",
    "# For cases where one vector is completely empty, avoid division by zero and replace by -1\n",
    "cosine_similarity = np.divide(dot_product, product_of_norm, out = np.full_like(dot_product, -1), where = product_of_norm!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[voxels_to_evaluate.index, 'third_cosine_similarity'] = cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the voxels which have changed **because** of class 1. We assume those are the ones for which the cosine similarity was low when considering all the class but is actually high if we don't consider the class 1. <br> (Note that the condition on the first cosine threshold is necessary since in condition C we ask wheter the distribution stays the same **and** that the class don't change. This keeps a lot of voxels which have a very high cosine similarity but which do not have exactly the same class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.change_criticity=='TBD') \\\n",
    "        & (df['third_cosine_similarity']>third_cosine_threshold) \\\n",
    "        & (df['cosine_similarity']<cos_threshold), 'change_criticity'] = 'class_1_specific'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='class_1_specific'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision F: Does the class 1 have a low presence in the new voxel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_points_prev = np.sum(df.iloc[:,df.columns.str.endswith('_prev')].values)\n",
    "nb_points_new = np.sum(df.iloc[:,df.columns.str.endswith('_new')].values)\n",
    "normalising_factor = nb_points_prev/nb_points_new\n",
    "class_1_new_normalised = df[df.change_criticity == 'class_1_specific']['1_new']*normalising_factor\n",
    "\n",
    "\n",
    "\n",
    "df.loc[class_1_new_normalised.index, 'change_criticity'] = np.where(class_1_new_normalised<threshold_class_1_presence,'non_prob-3', 'grey_zone-7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='non_prob-3'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='grey_zone-7'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision G: Is the change from (empty -> class x) | (class x -> empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['change_criticity']=='TBD') & (df['cosine_similarity']==-1) & (df.iloc[:,df.columns.str.endswith('_prev')].sum(axis=1).astype(bool)), 'change_criticity'] = 'disparition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity == 'disparition'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['change_criticity']=='TBD')& (df['cosine_similarity']==-1) & (df.iloc[:,df.columns.str.endswith('_new')].sum(axis=1).astype(bool)), 'change_criticity'] = 'apparition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity == 'apparition'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision H: do the neighbouring voxels contain also the new class (case of apparition/disparition)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newer method which consider the combination of the class present in all the neighbouring voxels, as opposed to the previous version where one neighbouring voxel had to be exactly similar for it to be considered non problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_neighbours(df, tree, kd_tree_query_radius, case='TBD'):\n",
    "    '''The cases can be: \n",
    "     -\"TBD\", we compare the new vox. occupancy with the new neighbours \n",
    "     -\"apparition\", we compare the new vox. occupancy with the previous neighbours occupancies\n",
    "     -\"disparition\", we compare the prev. vox. occupancy with the new neighbours occupancies'''\n",
    "    \n",
    "    def find_neighbours_occupancy(x, columns_to_compare):\n",
    "        # Given a voxel to evaluate, return the commbined occupancy of all its neighbours\n",
    "        return np.any(columns_to_compare[x].astype(bool),axis=0)\n",
    "\n",
    "    df = df.copy() \n",
    "\n",
    "    if case=='TBD':\n",
    "        to_evaluate, to_compare = 'new', 'new'\n",
    "    elif case == 'apparition':\n",
    "        to_evaluate, to_compare = 'new', 'prev'\n",
    "    elif case == 'disparition':\n",
    "        to_evaluate, to_compare = 'prev', 'new'\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    voxels_to_evaluate_df = df.loc[df.change_criticity == case]\n",
    "\n",
    "    # Query all ids of neighbours to the location to evaluate. This also returns the id of the voxel itself which must be removed\n",
    "    all_neighbours_ids = tree.query_radius(voxels_to_evaluate_df.loc[:, ['X_grid','Y_grid','Z_grid']].values, kd_tree_query_radius)\n",
    "\n",
    "    # Remove the id of the voxel itself in each neighbours sets\n",
    "    list_neighbours = []\n",
    "    for i in range(len(all_neighbours_ids)):\n",
    "        valid_neighbours_ids = all_neighbours_ids[i][all_neighbours_ids[i] != voxels_to_evaluate_df.index[i]]\n",
    "        list_neighbours.append(valid_neighbours_ids)\n",
    "    \n",
    "    # Select 'new' or 'prev' columns depending on the case\n",
    "    columns_to_compare = df.loc[:,df.columns.str.endswith(to_compare)].values\n",
    "    \n",
    "    neighbours_occupancy = np.asarray([find_neighbours_occupancy(sub_array, columns_to_compare) for sub_array in list_neighbours])\n",
    "\n",
    "    voxels_to_evaluate_bool = voxels_to_evaluate_df.loc[:, df.columns.str.endswith(to_evaluate)].values.astype(bool)\n",
    "    \n",
    "    # For each voxel to evaluate, check if the class present in it are also present in the neighbours\n",
    "    presence_in_neighbours = np.all(np.equal(voxels_to_evaluate_bool, (neighbours_occupancy & voxels_to_evaluate_bool)), axis=1)\n",
    "    \n",
    "    if case == 'disparition':\n",
    "        df.loc[df.change_criticity==case, 'change_criticity'] = np.where(presence_in_neighbours==True, 'non_prob-4', 'problematic-9')\n",
    "    elif case == 'apparition':\n",
    "        df.loc[df.change_criticity==case, 'change_criticity'] = np.where(presence_in_neighbours==True,'non_prob-5','problematic-10')\n",
    "    elif case == 'TBD':\n",
    "        df.loc[df.change_criticity==case, 'change_criticity'] = np.where(presence_in_neighbours==True, 'grey_zone-8', 'problematic-11')\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate KDTree for efficient neighbours research\n",
    "tree = KDTree(df[['X_grid','Y_grid','Z_grid']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL METHODOLOGY, LEFT FOR LEGACY\n",
    "\n",
    "# def compare_rows_apparition(voxel, df, tree, radius):\n",
    "#     # Should return True if a neighbour voxel had the same distribution we are observing in the appeared voxel, False otherwise\n",
    "\n",
    "#     neighbour_voxel_ids = tree.query_radius([[voxel.X_grid, voxel.Y_grid, voxel.Z_grid]], radius)[0]\n",
    "    \n",
    "#     new_vox_occupancy = voxel.iloc[voxel.index.str.endswith('_new')].values.astype(bool)\n",
    "\n",
    "#     for id in neighbour_voxel_ids:\n",
    "#         if np.all(new_vox_occupancy == df.iloc[id, df.columns.str.endswith('_prev')].values.astype(bool)): # Did the previous generation of the neighbouring voxel share the same characteristics as the new we are evaluating?\n",
    "\n",
    "#             return True\n",
    "\n",
    "#     return False\n",
    "\n",
    "# appeared_vox_status = df[df.change_criticity == 'apparition'].apply(lambda row: compare_rows_apparition(row, df, tree, radius=kd_tree_query_radius), axis=1)\n",
    "\n",
    "# df.loc[df.change_criticity=='apparition', 'change_criticity'] = np.where(appeared_vox_status==True,'non_prob-5','problematic-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW METHODOLOGY:\n",
    "df = compare_to_neighbours(df, tree, kd_tree_query_radius, case='apparition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='non_prob-5'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL METHODOLOGY, LEFT FOR LEGACY\n",
    "\n",
    "# def compare_rows_disparition(voxel,df,tree, radius):\n",
    "#     # Should return True if a neighbour voxel has the same distribution we were observing in the disappeared voxel, False otherwise\n",
    "#     neighbour_voxel_id = tree.query_radius([[voxel.X_grid, voxel.Y_grid, voxel.Z_grid]], radius)[0]\n",
    "    \n",
    "#     prev_vox_occupancy = voxel.iloc[voxel.index.str.endswith('_prev')].values.astype(bool)\n",
    "\n",
    "#     for id in neighbour_voxel_id:\n",
    "#         if np.all(prev_vox_occupancy == df.iloc[id, df.columns.str.endswith('_new')].values.astype(bool)): # Does the new generation of the neighbouring voxel share the same characteristics as the previous we are evaluating?\n",
    "#             return True\n",
    "\n",
    "#     return False\n",
    "\n",
    "# disappeared_vox_status=df[df.change_criticity == 'disparition'].apply(lambda row: compare_rows_disparition(row, df, tree, radius=kd_tree_query_radius),axis=1)\n",
    "\n",
    "# df.loc[df.change_criticity=='disparition', 'change_criticity'] = np.where(disappeared_vox_status==True, 'non_prob-4', 'problematic-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW METHODOLOGY:\n",
    "df = compare_to_neighbours(df, tree, kd_tree_query_radius, case='disparition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity == 'non_prob-4'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision I: do the neighbouring voxels contain also the new class (case of change of distribution)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL METHODOLOGY, LEFT FOR LEGACY\n",
    "\n",
    "# def compare_rows_change(voxel,df,tree, radius):\n",
    "#     # Should return True if a neighbour voxel has the same distribution we are observing in the current problematic voxel, False otherwise\n",
    "#     neighbour_voxel_id = tree.query_radius([[voxel.X_grid, voxel.Y_grid, voxel.Z_grid]], radius)[0]\n",
    "    \n",
    "#     vox_occupancy = voxel.iloc[voxel.index.str.endswith('_new')].values.astype(bool) # For the individual voxel, get the class occupancy \n",
    "\n",
    "#     for id in neighbour_voxel_id[neighbour_voxel_id!=voxel.name]: # Only consider the voxel in the neighborhood which are not the voxel itself\n",
    "#         if np.all(vox_occupancy == df.iloc[id, df.columns.str.endswith('_new')].values.astype(bool)): # Does the new generation of the neighbouring voxel share the same characteristics as the one we are evaluating?\n",
    "#             return True\n",
    "\n",
    "#     return False\n",
    "\n",
    "# changed_vox_status=df[df.change_criticity == 'TBD'].apply(lambda row: compare_rows_change(row, df, tree, radius=kd_tree_query_radius),axis=1)\n",
    "\n",
    "# df.loc[df.change_criticity=='TBD', 'change_criticity'] = np.where(changed_vox_status==True, 'grey_zone-8', 'problematic-11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW METHODOLOGY:\n",
    "df = compare_to_neighbours(df, tree, kd_tree_query_radius, case='TBD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='problematic-11'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='grey_zone-8'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision J: Additional check up for class 6 (building). If apparition, check if one voxels located exactly above contains class 6 and is non problematic\n",
    "This is to solve the problem of point appearing on the facades with a higher density LiDAR scanning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out which is the majority class in the voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['majority_class'] = df.iloc[:,df.columns.str.contains('_prev|_new')].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find for each planar grid cell the altitude of the highest point of class building \n",
    "highest_building_voxel_df = df[df['6_new']>0].groupby(['X_grid','Y_grid'])['Z_grid'].max()\\\n",
    "                            .to_frame('highest_building_voxel').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_building_voxel_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_building_voxel_df = highest_building_voxel_df.merge(df,\\\n",
    "                            left_on=['X_grid','Y_grid','highest_building_voxel'], right_on=['X_grid','Y_grid','Z_grid'],how='left') \\\n",
    "                            [['X_grid','Y_grid','highest_building_voxel','change_criticity']]\\\n",
    "                            .rename(columns={'change_criticity':'change_criticity_highest_building_voxel'})\n",
    "\n",
    "highest_building_voxel_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all voxel which have a problematic apparition of class building, match with the altitude of highest building point\n",
    "# in their planar grid cell\n",
    "temporary_df = df[(df.change_criticity=='problematic-10') & (df.majority_class=='6_new')].reset_index()\\\n",
    "                .merge(highest_building_voxel_df, how='left', on=['X_grid','Y_grid']).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_df[['X_grid','Y_grid','Z_grid','highest_building_voxel','change_criticity_highest_building_voxel']].tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of voxel for which the highest building voxel in their column is not problematic\n",
    "non_problematic_6_apparition_idx = temporary_df[temporary_df['change_criticity_highest_building_voxel'].str.contains('non_prob')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[non_problematic_6_apparition_idx, df.columns.get_loc('change_criticity')] = 'non_prob-6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.change_criticity=='non_prob-6'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change df so that the label and change_criticity are in a column of their own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change_criticity_label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['change_criticity_label'] = df.change_criticity.apply(lambda x: x.split(sep='-')[1]).astype(int)\n",
    "df['change_criticity'] = df.change_criticity.apply(lambda x: x.split(sep='-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the new dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_time = time.strftime(\"%d%m-%H%M\")\n",
    "\n",
    "csv_file_name = f'{tile_name}_{str(int(vox_height*100))}_{saving_time}.csv'\n",
    "df.to_csv(os.path.join(save_folder_path, csv_file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Save hyperparameters in JSON file with the same time as the .csv\n",
    "hyperparam_dict = {'first_cos_threshold' : cos_threshold,\n",
    "                    'second_cos_threshold' : second_cos_threshold,\n",
    "                    'third_cosine_threshold' : third_cosine_threshold,\n",
    "                    'query_radius' : kd_tree_query_radius,\n",
    "                    'class_1_presence_threshold':threshold_class_1_presence}\n",
    "\n",
    "json.dumps(hyperparam_dict)\n",
    "\n",
    "with open(os.path.join(save_folder_path, f\"{tile_name}_{str(int(vox_height*100))}_{saving_time}.json\"), \"w\") as outfile: \n",
    "    json.dump(hyperparam_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qalidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
